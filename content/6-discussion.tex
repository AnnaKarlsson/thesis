\chapter{DISCUSSION}\label{cha:discussion}
This chapter interweave the theory and method with the result. What the different is between the theory and result and why. The limits of the method used is also discussed.

\section{Accelerometer}
\subsection{Result}
The result of the first measurements of the accelerometer resulted in some unexpected result, thus the fact that JavaScripts listener without gravity doesn't seem to have any static noise at all. The reason for this is that it could be some software modification of the sensor data before it reaches the \texttt{event}. The recommendation from MEMS accelerometer manufacturers is to calibrate the sensors.~\cite[]{acc:kionixerr}\\ 
Doing some research on Android sensors their \texttt{SensorEvent} also have two types of accelerometer sensors that can be used: \\
\texttt{TYPE\_ACCELEROMETER} is the hardware measurements that measures the force of acceleration including the force of gravity with the SI unit $m/s^2$. \\
\texttt{TYPE\_LINEAR\_ACCELERATION} that is without gravity but that is a combined hardware and software sensor, thus this tests uses \texttt{TYPE\_ACCELEROMETER} were the measurements only comes from hardware. There have been some bias removal from the sensor such bias from different temperature. \cite[]{android:sensorEvent}\\
It would be a reasonable assumption that JavaScripts acceleration without gravity gets sensor data from Android's \texttt{TYPE\_ACCELEROMETER} and JavaScripts acceleration including gravity gets data from \texttt{TYPE\_LINEAR\_ACCELERATION}. Thus software calibrations or calculations has been done on the output event from the acceleration including gravity. This however is not anything that is public in any specifications such~\cite[]{sensor:W3Cspec} or~\cite[]{sensor:accIncludingGravity}.\\ 
As a result of measurements I the used measurement of the accelerometer is the one including gravity. \\
\\
As seen in the figures~\ref{fig:x50days}, ~\ref{fig:y50days} and ~\ref{fig:z50days} the \textit{Google Nexus 7} hasn't changed much over the 50 days compared to the \textit{Sony Xperia Z1 Compact} that especially has changed in the y-axis. The reason for the difference of accelerometer change over time may be due to the \textit{Google Nexus 7} only has been in the same place during those 50 days, thus only used when the tests were performed. Unlike the \textit{Sony Xperia} device that was used daily and may be dropped at one time or another. An additional fact about the measurements is that both devices has changed its OS between measurements 2 and 3, from Android version 4.4.4 to 5.1.1 and that different browser is used (Opera, Chrome and Firefox). Only the \textit{Sony Xperia} device had changed and not the \textit{Google Nexus}, which leads to the conclusion that OS version or browser doesn't matter noticeable and that the use of the device may affect the accelerometer.\\
\\
When comparing distances between the time features there are some values to discuss. The percentage that is calculated in table~\ref{tab:addlabel} is the percentage calculated to compare if the the distances of features between all 60 devices is larger than the distances between measurements of one device. If the min-distance has a percentage more than 100\% that means that there are different devices that have closer feature-distance than the once between one device, thus not a good candidate for fingerprinting. Average deviation, Kurtosis and Skewness were excluded from the table since their percentage were all to high (The min-distance in percent were higher than 100\%). The median distance of the features gives a value of the normal case of the measurements. For example the median mean-distance between all devices is ten times longer than the median mean-distance between the measurements of \textit{Nexus7}. Thus the lower percentage the lower risk of that another device has similar values. From this point of view the Mean, Maximum, Minimum and Median makes the best features of fingerprinting.

\subsection{Method}
As discussed in the beginning of the section above is the JavaScript or Android/iOS doing some calibration with the sensor that effects the result if not dealing with raw data. But as also mention is the data used in measurements II probably as raw data as you can get without reading from the accelerometer alone. If reading from the accelerometer directly would lead to doing more calibration before extracting the constant bias since no calibration of temperature and such is done.

\section{Gyroscope}
Discussion about the result of the gyroscope measurements and the method used to get gyroscope data from the mobile device.
\subsection{Result}
The first method used to compare the measurements were based on research of the accelerometer since there were no earlier research made on the gyroscope. This may affect the outcome since there may be other features that would have given better result. \\
The other method by calculating the Allan variance that is used for calibration of gyroscope may didn't gave that result that were expected. Since the variance often is used for gyroscope calibration it may be the case that it already is calculated and compensated for in the device.\\
\\
The gyroscope seems too much more sensitive in measurements than the accelerometer and therefore be harder to extract the constant bias. The fact that Android or JavaScript doesn't reveal information on what bias compensation that has been done before the developer get the measurement data makes that part harder. That the gyroscope is much more sensitive than the accelerometer can be seen when reading from table~\ref{tab:featureGyro} were the \textit{Sony Xperia Z1 Compact} device changed the min median distance with 75\% and the \textit{Google Nexus 7} only with 6\%. As the \textit{Sony Xperia} has been used over the fifty days of measurements. Compared to the \textit{Nexus} that only were used at the time of the measurements, thus didn't get dropped or else that could cause affected the hardware part of the device. \\
\\
A thing to take in account before the constant noise from the gyroscope is ruled out is if the sensor data gotten from JavaScript contains software calibrations or is the output data coming raw from the sensor. \\
In the Android developer page about sensor event \cite[]{android:sensorEvent} state that they make factory calibration and temperature compensation even on their uncalibrated sensor events of (only magnetometer and gyroscope) that is relativity new feature added in Android 4.3 Jelly Bean (API level 18~\cite{android:API18}) from 2013 but the original once used since Android 1.5 Cupcake (API level 3~\cite{android:API3}) from 2009 makes some more noise compensation and calibration. What kind of compensation and calibration done is not public. \\
Since the output of both the calibrated and uncalibrated sensor is in rad/s implies that it could be some software calibration in the date, not knowing where it is done.

\subsection{Method}
The method using JavaScripts listener to collect the data seems to work as expected. The question to ask is the same as for the accelerometer how much calibration and compensation of bias and drift already done before the software developers gets the output from the gyroscope. The positive thing about using JavaScript instead of developing an application is that the diversity of the collected devices is much better. It also gets easier to collect measurements since it is a web-page is much easier to spread and no installation is needed, in context to an application that has to be installed. The gain of using an Android application when measuring the gyroscope would be that Android provide an uncalibrated version of the gyroscope since 2013~\cite{android:API18}. This rawer data may result in better feature values in time domain or Allan variance.


\section{Camera}
This section discuss the result and method used for evaluate the camera sensor as a fingerprinting characteristic.
\subsection{Result}
The result of the camera sensor weren't as good as expected or as good as in the research by ~\cite[]{sensor:camera:DCIdent} were PRNU also was used. The significant differences is the use of a mobile device camera instead of a digital camera. Although the high level specification seems to be comparable with the digital cameras from 2009, since they had around 11 mega-pixels, an images size of around 4000x3000 pixels, and digital zoom of 4 times and had HD video recording width 30 fps.~\cite[]{gbg:kamera} This is about the average smart-phones camera today, but some other specifications may have other impact as ISO, optical zoom etc.

\subsection{Method}
The two methods used for collecting picture features had different advantages and disadvantages. The video-collecting done in connection to the second measurement were good in terms of measurability since it was easy to record a video of five seconds and just send. It generated in 100-200 which also made an enough pictures for a trait. On the other hand that lead to worse result in terms of uniqueness. \\
The second way of collecting data weren't as good in terms of measurability but it god slightly more uniqueness but far from good enough.


\section{The work in a wider context}\label{sec:ethical}
There is a lot of discuss in terms of privacy and integrity when dealing with the sensor of the device. To begin with neither of the motion sensors require any permission to read when visiting a web-page. If there is an easy way of identifying a device by a sensor the days of using cookies will be long gone. Which of course can have advantage in terms of user-ability, but as valuable your personal information is today for the commercial and advertising itâ€™s hard to set a value for something that could identify you everywhere on the Internet. The tracking possibilities is enormous and has to be concerned if this type of identifying can be done. \\
\\
There are of course some good things in the view of ethical and societal aspects. If the sensor-data is used as aimed in this thesis it gain privacy and integrity since the possibility of more secure authentication both between human and machine and M2M. Because, you want such that it's really any of your heat sensors that send signals to your thermostat, or that it is only your mobile that can unlock the front door.\\
\\
The point here is that fingerprinting features of a device should be treated in the same way as your biometric trait. This means that if you must have control over were the biometric trait is used. Most of us think that it is legit that Authority used our fingerprint if it gain in a more secure society. On the other hand most of us don't want our fingerprints to be used in commercial purposes. \\
The concept should be considered when fingerprinting a device as well. The accelerometer data may be applicable to use by banks, to your door or car. But you may not want is as a login feature to a commercial site that may sell that information.